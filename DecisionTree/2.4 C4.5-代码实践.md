# C4.5代码实践

C4.5是基于ID3上的改进 因此代码设计上也继承`DecisionTreeID3`

在ID3的基础上 做了如下优化

1. 缺失值处理
2. 连续值处理
3. 使用信息增益率作为划分标准
4. *剪枝 (因未使用验证集 故暂未加入)*

#### 基本形式

定义一个类 `DecisionTreeC45`

输入

​		与`DecisionTreeID3`保持一致

输出

​		与`DecisionTreeID3`保持一致

#### 复现要点

使用信息增益率作为划分标准 修改起来非常的简单

主要是缺失值与连续值的处理上

缺失值处理上引入了样本权重  

其实ID3-决策树中默认样本权重都一样 大家都是1

连续值的处理上与类别型也略有不同

一个类别型特征仅需计算当前特征下的信息增益与信息增益率

而一个连续型特征需要计算该特征二分法后各个特征值的信息增益与信息增益率

#### 复现逻辑

##### 缺失值处理

```python
# 划分数据时是否加入空值
# 若加入 则同时更新空值的权重
def _split_df(self, data_df, field, field_value, add_na=False):
    df_field_df = data_df[data_df[field] == field_value]
    if add_na:
        df_null_df = data_df[data_df[field].isnull()]
        df_null_df[self.feature_rate_field] = df_null_df[self.feature_rate_field] * df_field_df.shape[0] / (
                data_df.shape[0] - df_null_df.shape[0])
        df_field_df = pd.concat([df_field_df, df_null_df])

    return df_field_df.drop(field, axis=1)
 
# 计算信息熵时 不再计算不同label的个数
# 直接对权重求和即可
def _get_entropy(self, data_df, label):
    data_num = data_df.shape[0]
    entropy_value = -data_df.groupby(label).sum()[self.feature_rate_field].apply(
        lambda x: x / data_num * log2(x / data_num)).sum()
```

##### 连续值处理

```python
# 定义类别型信息增益类
InfoGainRatioCateFeature = namedtuple('InfoGainRatioFeature',
                                      ['type', 'feature', 'info_gain_ratio','info_gain'])

# 定义数值型信息增益类
# 比类别型增加一个feature_value 用于记录二分法后的特征值
InfoGainRatioNumFeature = namedtuple('InfoGainRatioFeature',
                                     ['type', 'feature', 'feature_value','info_gain_ratio', 'info_gain'])  
                                     
  
# 获取数值型的信息增益及信息增益率
def _get_num_feature_entropy(self, data_df, feature):
    info_gain_ratio_list = []
    data_num = data_df.shape[0]
    data_not_null_df = data_df[data_df[feature].notnull()]
    data_not_null_num = data_not_null_df.shape[0]
    base_entropy = self._get_entropy(data_not_null_df, self.label)
    num_feature_value_list = data_not_null_df[feature].sort_values().unique().tolist()
    feature_value_list = [round((num_feature_value_list[i] + num_feature_value_list[i + 1]) / 2, 3) for i in
                          range(len(num_feature_value_list) - 1)]

    for feature_value in feature_value_list:
        lt_df = data_not_null_df[data_not_null_df[feature] <= feature_value]
        gt_df = data_not_null_df[data_not_null_df[feature] > feature_value]
        lt_prob = lt_df.shape[0] / data_not_null_df.shape[0]
        gt_prob = gt_df.shape[0] / data_not_null_df.shape[0]
        new_entropy = lt_prob * self._get_entropy(lt_df,
                                                  self.label) + gt_prob * self._get_entropy(gt_df,
                                                                                            self.label)

        info_gain = round((base_entropy - new_entropy) * (data_not_null_num / data_num), 4)
        iv = -(lt_prob * log2(lt_prob) + gt_prob * log2(gt_prob))
        info_gain_ratio = round(info_gain / iv, 4)
        info_gain_ratio_list.append(
            self.InfoGainRatioNumFeature('num', feature, feature_value, info_gain_ratio, info_gain))

    return info_gain_ratio_list

# 获取类别型的信息增益及信息增益率
def _get_cate_feature_entropy(self, data_df, feature):

    data_not_null_df = data_df[data_df[feature].notnull()]
    base_entropy = self._get_entropy(data_not_null_df, self.label)
    base_entropy_rate = data_not_null_df[self.feature_rate_field].sum() / data_df[self.feature_rate_field].sum()
    new_entropy = 0
    for feature_value in data_not_null_df[feature].unique():
        sub_data_df = self._split_df(data_df, feature, feature_value)
        prob = sub_data_df[self.feature_rate_field].sum() / data_not_null_df[self.feature_rate_field].sum()
        new_entropy += prob * self._get_entropy(sub_data_df, self.label)
    iv = self._get_entropy(data_not_null_df, feature)
    info_gain = round(base_entropy_rate * (base_entropy - new_entropy), 4)
    info_gain_ratio = round(info_gain / iv, 4)
    return self.InfoGainRatioCateFeature('cate', feature, info_gain_ratio, info_gain)  
                                     
```

##### 最优划分点

```python
# 选择最优特征作为划分点
def choose_best_feature(self, data_df, feature_list):
    info_gain_feature_list = []
    for feature in feature_list:
        if data_df[feature].dtypes in ('float', 'int'):
            info_gain_feature_list.extend(self._get_num_feature_entropy(data_df, feature))
        else:
            info_gain_feature_list.append(self._get_cate_feature_entropy(data_df, feature))

    info_gain_avg = sum([i.info_gain for i in info_gain_feature_list]) / len(info_gain_feature_list)
    return sorted([i for i in info_gain_feature_list if i.info_gain >= info_gain_avg], key=lambda x: x.info_gain_ratio,
                  reverse=True)[0]  
```

##### 完整代码

[Github](https://github.com/sadjjk/Machine-Learning/blob/master/DecisionTree/DecisionTreeC45.py)

##### 代码效果

以自(瞎)创(编)的西瓜数据集为例

| 编号 | 色泽 | 根蒂 | 敲声 | 纹理 | 脐部 | 触感 | 密度  | 好瓜(标签) |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ----- | ---------- |
| 1    | NULL | 蜷缩 | 浊响 | 清晰 | 凹陷 | 硬滑 | 0.697 | 是         |
| 2    | 乌黑 | 蜷缩 | 沉闷 | 清晰 | 凹陷 | NULL | 0.774 | 是         |
| 3    | 乌黑 | 蜷缩 | NULL | 清晰 | 凹陷 | 硬滑 | 0.634 | 是         |
| 4    | 青绿 | 蜷缩 | 沉闷 | 清晰 | 凹陷 | 硬滑 | 0.608 | 是         |
| 5    | NULL | 蜷缩 | 浊响 | 清晰 | 凹陷 | 硬滑 | 0.556 | 是         |
| 6    | 青绿 | 稍蜷 | 浊响 | 清晰 | NULL | 软粘 | 0.403 | 是         |
| 7    | 乌黑 | 稍蜷 | 浊响 | 稍糊 | 稍凹 | 软粘 | 0.481 | 是         |
| 8    | 乌黑 | 稍蜷 | 浊响 | NULL | 稍凹 | 硬滑 | 0.437 | 是         |
| 9    | 乌黑 | NULL | 沉闷 | 稍糊 | 稍凹 | 硬滑 | 0.666 | 否         |
| 10   | 青绿 | 硬挺 | 清脆 | NULL | 平坦 | 软粘 | 0.243 | 否         |
| 11   | 浅白 | 硬挺 | 清脆 | 模糊 | 平坦 | NULL | 0.245 | 否         |
| 12   | 浅白 | 蜷缩 | NULL | 模糊 | 平坦 | 软粘 | 0.343 | 否         |
| 13   | NULL | 稍蜷 | 浊响 | 稍糊 | 凹陷 | 硬滑 | 0.639 | 否         |
| 14   | 浅白 | 稍蜷 | 沉闷 | 稍糊 | 凹陷 | 硬滑 | 0.657 | 否         |
| 15   | 乌黑 | 稍蜷 | 浊响 | 清晰 | NULL | 软粘 | 0.36  | 否         |
| 16   | 浅白 | 蜷缩 | 浊响 | 模糊 | 平坦 | 硬滑 | 0.593 | 否         |
| 17   | 青绿 | NULL | 沉闷 | 稍糊 | 稍凹 | 硬滑 | 0.719 | 否         |

代码运行效果

![img](https://i.loli.net/2021/09/27/7KJT8sBAZfzc1nL.png)